[10/20 13:52:40] LGKD INFO: [!] starting logging at directory ./logs/100-50-ade/LGKD/step0
[10/20 13:52:40] LGKD INFO: Training step 0 with lr 0.02.
[10/20 13:55:57] LGKD INFO: Dataset: ade, Train set: 20192, Val set: 2000, Test set: 2000, n_classes 101
[10/20 13:55:57] LGKD INFO: Total batch size is 6
[10/20 13:55:57] LGKD INFO: Backbone: swin_b
[10/20 13:55:59] LGKD INFO: [!] Model made with pre-trained
[10/20 13:55:59] LGKD INFO: *** Test the model on all seen classes...
[10/20 13:56:02] LGKD INFO: *** Model restored from /root/autodl-tmp/lyc/LGKD+swin/checkpoints/step/100-10-ade_LGKD_0.pth at epoch 60.
[10/20 13:59:25] LGKD INFO: Validation, Class Loss=0.9389946460723877, Reg Loss=0.0 (without scaling)
[10/20 13:59:25] LGKD INFO: Done test
[10/20 13:59:25] LGKD INFO: *** End of Test, Total Loss=0.9389946460723877, Class Loss=0.9389946460723877, Reg Loss=0.0
[10/20 13:59:25] LGKD INFO: 
Total samples: 2000.000000
Overall Acc: 0.747507
Mean Acc: 0.553113
FreqW Acc: 0.612199
Mean IoU: 0.426212
Class IoU:
	class 0: 0.37589908
	class 1: 0.66366124
	class 2: 0.7605292
	class 3: 0.91243565
	class 4: 0.71195847
	class 5: 0.68793607
	class 6: 0.7630401
	class 7: 0.78080744
	class 8: 0.7473785
	class 9: 0.5578162
	class 10: 0.5845282
	class 11: 0.51006687
	class 12: 0.5608655
	class 13: 0.6718731
	class 14: 0.28597686
	class 15: 0.333503
	class 16: 0.44107553
	class 17: 0.5335897
	class 18: 0.4079281
	class 19: 0.63699144
	class 20: 0.4463701
	class 21: 0.7372392
	class 22: 0.45354334
	class 23: 0.5601363
	class 24: 0.5530417
	class 25: 0.36305392
	class 26: 0.42123917
	class 27: 0.68331784
	class 28: 0.564246
	class 29: 0.50601083
	class 30: 0.3791522
	class 31: 0.34733188
	class 32: 0.5253539
	class 33: 0.36963722
	class 34: 0.376328
	class 35: 0.38803548
	class 36: 0.4393799
	class 37: 0.37318298
	class 38: 0.66438544
	class 39: 0.27695027
	class 40: 0.4627521
	class 41: 0.115007915
	class 42: 0.09547388
	class 43: 0.28888884
	class 44: 0.26983416
	class 45: 0.399547
	class 46: 0.1885698
	class 47: 0.37770718
	class 48: 0.6007898
	class 49: 0.54436094
	class 50: 0.6026051
	class 51: 0.5176397
	class 52: 0.40254247
	class 53: 0.20298864
	class 54: 0.23759757
	class 55: 0.52159286
	class 56: 0.4355714
	class 57: 0.8298802
	class 58: 0.43812025
	class 59: 0.46328738
	class 60: 0.30233133
	class 61: 0.28529298
	class 62: 0.36462793
	class 63: 0.37504843
	class 64: 0.32516253
	class 65: 0.4512331
	class 66: 0.6934225
	class 67: 0.30214274
	class 68: 0.36183724
	class 69: 0.11164218
	class 70: 0.32835668
	class 71: 0.49843356
	class 72: 0.569856
	class 73: 0.49650523
	class 74: 0.25973225
	class 75: 0.4890929
	class 76: 0.33195946
	class 77: 0.23905447
	class 78: 0.23777004
	class 79: 0.43823305
	class 80: 0.38599974
	class 81: 0.7525906
	class 82: 0.40852776
	class 83: 0.2554294
	class 84: 0.21164726
	class 85: 0.3947851
	class 86: 0.53023523
	class 87: 0.19626641
	class 88: 0.07665344
	class 89: 0.2671234
	class 90: 0.49141464
	class 91: 0.5721605
	class 92: 0.09343068
	class 93: 0.1915912
	class 94: 0.060148012
	class 95: 0.021555914
	class 96: 0.033295315
	class 97: 0.36776888
	class 98: 0.25314647
	class 99: 0.3059103
	class 100: 0.36548382
Class Acc:
	class 0: 0.5359205
	class 1: 0.8215277
	class 2: 0.8855858
	class 3: 0.96069914
	class 4: 0.8512008
	class 5: 0.8345208
	class 6: 0.89066035
	class 7: 0.87694675
	class 8: 0.9200997
	class 9: 0.73663825
	class 10: 0.7471242
	class 11: 0.6296567
	class 12: 0.7364416
	class 13: 0.85382056
	class 14: 0.38612485
	class 15: 0.4553246
	class 16: 0.6081453
	class 17: 0.6928341
	class 18: 0.53086245
	class 19: 0.80641615
	class 20: 0.5976469
	class 21: 0.86431587
	class 22: 0.5887865
	class 23: 0.73853225
	class 24: 0.7358357
	class 25: 0.54359496
	class 26: 0.57455736
	class 27: 0.8466962
	class 28: 0.6770586
	class 29: 0.6073302
	class 30: 0.6138383
	class 31: 0.520716
	class 32: 0.69409305
	class 33: 0.49428803
	class 34: 0.56578165
	class 35: 0.5652852
	class 36: 0.6323986
	class 37: 0.49279428
	class 38: 0.7667889
	class 39: 0.3904822
	class 40: 0.5937124
	class 41: 0.14446464
	class 42: 0.13105276
	class 43: 0.35561517
	class 44: 0.38285708
	class 45: 0.5949211
	class 46: 0.2658408
	class 47: 0.44365978
	class 48: 0.72929823
	class 49: 0.7289135
	class 50: 0.8054373
	class 51: 0.6636889
	class 52: 0.5827764
	class 53: 0.3180321
	class 54: 0.31061748
	class 55: 0.6925414
	class 56: 0.55372125
	class 57: 0.9565806
	class 58: 0.5429041
	class 59: 0.5366685
	class 60: 0.45353296
	class 61: 0.49721918
	class 62: 0.5383859
	class 63: 0.5649947
	class 64: 0.36629823
	class 65: 0.66096044
	class 66: 0.82777447
	class 67: 0.4158439
	class 68: 0.5126569
	class 69: 0.17567928
	class 70: 0.38293713
	class 71: 0.66591555
	class 72: 0.73185265
	class 73: 0.69637775
	class 74: 0.5990992
	class 75: 0.6020716
	class 76: 0.48733675
	class 77: 0.27815545
	class 78: 0.30339995
	class 79: 0.45365354
	class 80: 0.42358965
	class 81: 0.85718316
	class 82: 0.48203346
	class 83: 0.30545744
	class 84: 0.3135899
	class 85: 0.49205184
	class 86: 0.69140714
	class 87: 0.25025344
	class 88: 0.086688966
	class 89: 0.27769148
	class 90: 0.6624104
	class 91: 0.834122
	class 92: 0.20956646
	class 93: 0.3013049
	class 94: 0.086939774
	class 95: 0.032554667
	class 96: 0.055196773
	class 97: 0.4406152
	class 98: 0.36219198
	class 99: 0.44657302
	class 100: 0.4341924

[10/20 13:59:25] LGKD INFO: Closing the Writer.
[10/20 14:11:35] LGKD INFO: [!] starting logging at directory ./logs/100-50-ade/LGKD/step0
[10/20 14:11:35] LGKD INFO: Training step 0 with lr 0.02.
[10/20 14:11:35] LGKD INFO: Dataset: ade, Train set: 20192, Val set: 2000, Test set: 2000, n_classes 101
[10/20 14:11:35] LGKD INFO: Total batch size is 6
[10/20 14:11:35] LGKD INFO: Backbone: swin_b
[10/20 14:11:36] LGKD INFO: [!] Model made with pre-trained
[10/20 14:11:36] LGKD INFO: *** Test the model on all seen classes...
[10/20 14:11:40] LGKD INFO: *** Model restored from /root/autodl-tmp/lyc/LGKD+swin/checkpoints/step/100-10-ade_LGKD_0.pth at epoch 60.
[10/20 14:15:02] LGKD INFO: Validation, Class Loss=0.9389946460723877, Reg Loss=0.0 (without scaling)
[10/20 14:15:02] LGKD INFO: Done test
[10/20 14:15:02] LGKD INFO: *** End of Test, Total Loss=0.9389946460723877, Class Loss=0.9389946460723877, Reg Loss=0.0
[10/20 14:15:02] LGKD INFO: 
Total samples: 2000.000000
Overall Acc: 0.747507
Mean Acc: 0.553113
FreqW Acc: 0.612199
Mean IoU: 0.426212
Class IoU:
	class 0: 0.37589908
	class 1: 0.66366124
	class 2: 0.7605292
	class 3: 0.91243565
	class 4: 0.71195847
	class 5: 0.68793607
	class 6: 0.7630401
	class 7: 0.78080744
	class 8: 0.7473785
	class 9: 0.5578162
	class 10: 0.5845282
	class 11: 0.51006687
	class 12: 0.5608655
	class 13: 0.6718731
	class 14: 0.28597686
	class 15: 0.333503
	class 16: 0.44107553
	class 17: 0.5335897
	class 18: 0.4079281
	class 19: 0.63699144
	class 20: 0.4463701
	class 21: 0.7372392
	class 22: 0.45354334
	class 23: 0.5601363
	class 24: 0.5530417
	class 25: 0.36305392
	class 26: 0.42123917
	class 27: 0.68331784
	class 28: 0.564246
	class 29: 0.50601083
	class 30: 0.3791522
	class 31: 0.34733188
	class 32: 0.5253539
	class 33: 0.36963722
	class 34: 0.376328
	class 35: 0.38803548
	class 36: 0.4393799
	class 37: 0.37318298
	class 38: 0.66438544
	class 39: 0.27695027
	class 40: 0.4627521
	class 41: 0.115007915
	class 42: 0.09547388
	class 43: 0.28888884
	class 44: 0.26983416
	class 45: 0.399547
	class 46: 0.1885698
	class 47: 0.37770718
	class 48: 0.6007898
	class 49: 0.54436094
	class 50: 0.6026051
	class 51: 0.5176397
	class 52: 0.40254247
	class 53: 0.20298864
	class 54: 0.23759757
	class 55: 0.52159286
	class 56: 0.4355714
	class 57: 0.8298802
	class 58: 0.43812025
	class 59: 0.46328738
	class 60: 0.30233133
	class 61: 0.28529298
	class 62: 0.36462793
	class 63: 0.37504843
	class 64: 0.32516253
	class 65: 0.4512331
	class 66: 0.6934225
	class 67: 0.30214274
	class 68: 0.36183724
	class 69: 0.11164218
	class 70: 0.32835668
	class 71: 0.49843356
	class 72: 0.569856
	class 73: 0.49650523
	class 74: 0.25973225
	class 75: 0.4890929
	class 76: 0.33195946
	class 77: 0.23905447
	class 78: 0.23777004
	class 79: 0.43823305
	class 80: 0.38599974
	class 81: 0.7525906
	class 82: 0.40852776
	class 83: 0.2554294
	class 84: 0.21164726
	class 85: 0.3947851
	class 86: 0.53023523
	class 87: 0.19626641
	class 88: 0.07665344
	class 89: 0.2671234
	class 90: 0.49141464
	class 91: 0.5721605
	class 92: 0.09343068
	class 93: 0.1915912
	class 94: 0.060148012
	class 95: 0.021555914
	class 96: 0.033295315
	class 97: 0.36776888
	class 98: 0.25314647
	class 99: 0.3059103
	class 100: 0.36548382
Class Acc:
	class 0: 0.5359205
	class 1: 0.8215277
	class 2: 0.8855858
	class 3: 0.96069914
	class 4: 0.8512008
	class 5: 0.8345208
	class 6: 0.89066035
	class 7: 0.87694675
	class 8: 0.9200997
	class 9: 0.73663825
	class 10: 0.7471242
	class 11: 0.6296567
	class 12: 0.7364416
	class 13: 0.85382056
	class 14: 0.38612485
	class 15: 0.4553246
	class 16: 0.6081453
	class 17: 0.6928341
	class 18: 0.53086245
	class 19: 0.80641615
	class 20: 0.5976469
	class 21: 0.86431587
	class 22: 0.5887865
	class 23: 0.73853225
	class 24: 0.7358357
	class 25: 0.54359496
	class 26: 0.57455736
	class 27: 0.8466962
	class 28: 0.6770586
	class 29: 0.6073302
	class 30: 0.6138383
	class 31: 0.520716
	class 32: 0.69409305
	class 33: 0.49428803
	class 34: 0.56578165
	class 35: 0.5652852
	class 36: 0.6323986
	class 37: 0.49279428
	class 38: 0.7667889
	class 39: 0.3904822
	class 40: 0.5937124
	class 41: 0.14446464
	class 42: 0.13105276
	class 43: 0.35561517
	class 44: 0.38285708
	class 45: 0.5949211
	class 46: 0.2658408
	class 47: 0.44365978
	class 48: 0.72929823
	class 49: 0.7289135
	class 50: 0.8054373
	class 51: 0.6636889
	class 52: 0.5827764
	class 53: 0.3180321
	class 54: 0.31061748
	class 55: 0.6925414
	class 56: 0.55372125
	class 57: 0.9565806
	class 58: 0.5429041
	class 59: 0.5366685
	class 60: 0.45353296
	class 61: 0.49721918
	class 62: 0.5383859
	class 63: 0.5649947
	class 64: 0.36629823
	class 65: 0.66096044
	class 66: 0.82777447
	class 67: 0.4158439
	class 68: 0.5126569
	class 69: 0.17567928
	class 70: 0.38293713
	class 71: 0.66591555
	class 72: 0.73185265
	class 73: 0.69637775
	class 74: 0.5990992
	class 75: 0.6020716
	class 76: 0.48733675
	class 77: 0.27815545
	class 78: 0.30339995
	class 79: 0.45365354
	class 80: 0.42358965
	class 81: 0.85718316
	class 82: 0.48203346
	class 83: 0.30545744
	class 84: 0.3135899
	class 85: 0.49205184
	class 86: 0.69140714
	class 87: 0.25025344
	class 88: 0.086688966
	class 89: 0.27769148
	class 90: 0.6624104
	class 91: 0.834122
	class 92: 0.20956646
	class 93: 0.3013049
	class 94: 0.086939774
	class 95: 0.032554667
	class 96: 0.055196773
	class 97: 0.4406152
	class 98: 0.36219198
	class 99: 0.44657302
	class 100: 0.4341924

[10/20 14:15:02] LGKD INFO: Closing the Writer.
[10/20 16:46:41] LGKD INFO: [!] starting logging at directory ./logs/100-50-ade/LGKD/step0
[10/20 16:46:41] LGKD INFO: Training step 0 with lr 0.02.
[10/20 16:46:42] LGKD INFO: Dataset: ade, Train set: 20192, Val set: 2000, Test set: 2000, n_classes 101
[10/20 16:46:42] LGKD INFO: Total batch size is 16
[10/20 16:46:42] LGKD INFO: Backbone: swin_b
[10/20 16:46:43] LGKD INFO: [!] Model made with pre-trained
[10/20 16:46:43] LGKD INFO: *** Test the model on all seen classes...
[10/20 16:46:46] LGKD INFO: *** Model restored from /root/autodl-tmp/lyc/LGKD+swin/checkpoints/step/100-10-ade_LGKD_0.pth at epoch 60.
[10/20 16:50:12] LGKD INFO: Validation, Class Loss=0.9384108781814575, Reg Loss=0.0 (without scaling)
[10/20 16:50:12] LGKD INFO: Done test
[10/20 16:50:12] LGKD INFO: *** End of Test, Total Loss=0.9384108781814575, Class Loss=0.9384108781814575, Reg Loss=0.0
[10/20 16:50:12] LGKD INFO: 
Total samples: 2000.000000
Overall Acc: 0.747507
Mean Acc: 0.553111
FreqW Acc: 0.612198
Mean IoU: 0.426209
Class IoU:
	class 0: 0.37590846
	class 1: 0.66365814
	class 2: 0.760525
	class 3: 0.9124393
	class 4: 0.7119502
	class 5: 0.6879413
	class 6: 0.7630421
	class 7: 0.78080606
	class 8: 0.7473858
	class 9: 0.55782235
	class 10: 0.58451927
	class 11: 0.5100579
	class 12: 0.5608425
	class 13: 0.67186624
	class 14: 0.2859864
	class 15: 0.33349368
	class 16: 0.44107023
	class 17: 0.533591
	class 18: 0.40794063
	class 19: 0.6369821
	class 20: 0.44638622
	class 21: 0.73725355
	class 22: 0.45352596
	class 23: 0.5601405
	class 24: 0.55303675
	class 25: 0.36305207
	class 26: 0.42123997
	class 27: 0.6832902
	class 28: 0.5642341
	class 29: 0.50598735
	class 30: 0.37915364
	class 31: 0.34732485
	class 32: 0.5253317
	class 33: 0.36966497
	class 34: 0.37636596
	class 35: 0.3880517
	class 36: 0.43943575
	class 37: 0.37318087
	class 38: 0.66437876
	class 39: 0.27696833
	class 40: 0.46278659
	class 41: 0.11501391
	class 42: 0.09548542
	class 43: 0.28886658
	class 44: 0.26981914
	class 45: 0.39956892
	class 46: 0.18857789
	class 47: 0.37770313
	class 48: 0.6007592
	class 49: 0.5443519
	class 50: 0.6025931
	class 51: 0.5176029
	class 52: 0.4024705
	class 53: 0.20299438
	class 54: 0.23760086
	class 55: 0.52160454
	class 56: 0.4355887
	class 57: 0.829871
	class 58: 0.4380976
	class 59: 0.4632953
	class 60: 0.30230862
	class 61: 0.28533775
	class 62: 0.36464185
	class 63: 0.37506878
	class 64: 0.32512954
	class 65: 0.45122153
	class 66: 0.69343597
	class 67: 0.30219898
	class 68: 0.36181638
	class 69: 0.1116176
	class 70: 0.32830787
	class 71: 0.49841103
	class 72: 0.5698284
	class 73: 0.49645004
	class 74: 0.2597292
	class 75: 0.48911268
	class 76: 0.33191437
	class 77: 0.23906495
	class 78: 0.23778039
	class 79: 0.4382537
	class 80: 0.38597485
	class 81: 0.7526202
	class 82: 0.40862325
	class 83: 0.25538394
	class 84: 0.2116096
	class 85: 0.39480972
	class 86: 0.530239
	class 87: 0.1962491
	class 88: 0.07664955
	class 89: 0.26716444
	class 90: 0.49141425
	class 91: 0.5721125
	class 92: 0.09336828
	class 93: 0.19150744
	class 94: 0.06012751
	class 95: 0.021527996
	class 96: 0.03334064
	class 97: 0.3677725
	class 98: 0.2531903
	class 99: 0.3058627
	class 100: 0.36545247
Class Acc:
	class 0: 0.53592896
	class 1: 0.8215274
	class 2: 0.8855843
	class 3: 0.9607003
	class 4: 0.85119647
	class 5: 0.8345219
	class 6: 0.8906581
	class 7: 0.8769442
	class 8: 0.92010254
	class 9: 0.73663706
	class 10: 0.7471149
	class 11: 0.629648
	class 12: 0.7364226
	class 13: 0.8538082
	class 14: 0.38614458
	class 15: 0.45532572
	class 16: 0.6081356
	class 17: 0.69282025
	class 18: 0.53087157
	class 19: 0.80641824
	class 20: 0.5976656
	class 21: 0.8643365
	class 22: 0.5887753
	class 23: 0.7385385
	class 24: 0.7358259
	class 25: 0.5435822
	class 26: 0.5745559
	class 27: 0.84667546
	class 28: 0.67704326
	class 29: 0.6073121
	class 30: 0.6138547
	class 31: 0.5207115
	class 32: 0.69408244
	class 33: 0.49432942
	class 34: 0.5658006
	class 35: 0.5652981
	class 36: 0.6324338
	class 37: 0.49280417
	class 38: 0.7667817
	class 39: 0.39050627
	class 40: 0.59375834
	class 41: 0.14447097
	class 42: 0.13106944
	class 43: 0.35556778
	class 44: 0.38285512
	class 45: 0.5949357
	class 46: 0.26585144
	class 47: 0.44365105
	class 48: 0.7292926
	class 49: 0.7288952
	class 50: 0.8054773
	class 51: 0.66365594
	class 52: 0.5826923
	class 53: 0.31802928
	class 54: 0.31063592
	class 55: 0.6925443
	class 56: 0.5537089
	class 57: 0.956583
	class 58: 0.54287255
	class 59: 0.53667825
	class 60: 0.4534933
	class 61: 0.49729204
	class 62: 0.538397
	class 63: 0.5650384
	class 64: 0.36627632
	class 65: 0.66095436
	class 66: 0.8277886
	class 67: 0.41593623
	class 68: 0.5126156
	class 69: 0.17565991
	class 70: 0.38288757
	class 71: 0.66593015
	class 72: 0.73180825
	class 73: 0.6963157
	class 74: 0.59910506
	class 75: 0.60207707
	class 76: 0.48720375
	class 77: 0.27817735
	class 78: 0.30340102
	class 79: 0.4536916
	class 80: 0.42357424
	class 81: 0.8571664
	class 82: 0.48212284
	class 83: 0.30539942
	class 84: 0.31351915
	class 85: 0.49207014
	class 86: 0.69141525
	class 87: 0.25026768
	class 88: 0.086682945
	class 89: 0.27774173
	class 90: 0.6623786
	class 91: 0.8341048
	class 92: 0.20941311
	class 93: 0.30127367
	class 94: 0.086926796
	class 95: 0.032517504
	class 96: 0.055277545
	class 97: 0.44064367
	class 98: 0.36225468
	class 99: 0.44654596
	class 100: 0.43421322

[10/20 16:50:12] LGKD INFO: Closing the Writer.
[10/20 17:15:39] LGKD INFO: [!] starting logging at directory ./logs/100-50-ade/LGKD/step0
[10/20 17:15:39] LGKD INFO: Training step 0 with lr 0.02.
[10/20 17:15:39] LGKD INFO: Dataset: ade, Train set: 20192, Val set: 2000, Test set: 2000, n_classes 101
[10/20 17:15:39] LGKD INFO: Total batch size is 16
[10/20 17:15:39] LGKD INFO: Backbone: swin_b
[10/20 17:15:40] LGKD INFO: [!] Model made with pre-trained
[10/20 17:15:40] LGKD INFO: *** Test the model on all seen classes...
[10/20 17:15:43] LGKD INFO: *** Model restored from /root/autodl-tmp/lyc/LGKD+swin/checkpoints/step/100-10-ade_LGKD_0.pth at epoch 60.
[10/20 17:19:04] LGKD INFO: Validation, Class Loss=0.9384108781814575, Reg Loss=0.0 (without scaling)
[10/20 17:19:04] LGKD INFO: Done test
[10/20 17:19:04] LGKD INFO: *** End of Test, Total Loss=0.9384108781814575, Class Loss=0.9384108781814575, Reg Loss=0.0
[10/20 17:19:04] LGKD INFO: 
Total samples: 2000.000000
Overall Acc: 0.747507
Mean Acc: 0.553111
FreqW Acc: 0.612198
Mean IoU: 0.426209
Class IoU:
	class 0: 0.37590846
	class 1: 0.66365814
	class 2: 0.760525
	class 3: 0.9124393
	class 4: 0.7119502
	class 5: 0.6879413
	class 6: 0.7630421
	class 7: 0.78080606
	class 8: 0.7473858
	class 9: 0.55782235
	class 10: 0.58451927
	class 11: 0.5100579
	class 12: 0.5608425
	class 13: 0.67186624
	class 14: 0.2859864
	class 15: 0.33349368
	class 16: 0.44107023
	class 17: 0.533591
	class 18: 0.40794063
	class 19: 0.6369821
	class 20: 0.44638622
	class 21: 0.73725355
	class 22: 0.45352596
	class 23: 0.5601405
	class 24: 0.55303675
	class 25: 0.36305207
	class 26: 0.42123997
	class 27: 0.6832902
	class 28: 0.5642341
	class 29: 0.50598735
	class 30: 0.37915364
	class 31: 0.34732485
	class 32: 0.5253317
	class 33: 0.36966497
	class 34: 0.37636596
	class 35: 0.3880517
	class 36: 0.43943575
	class 37: 0.37318087
	class 38: 0.66437876
	class 39: 0.27696833
	class 40: 0.46278659
	class 41: 0.11501391
	class 42: 0.09548542
	class 43: 0.28886658
	class 44: 0.26981914
	class 45: 0.39956892
	class 46: 0.18857789
	class 47: 0.37770313
	class 48: 0.6007592
	class 49: 0.5443519
	class 50: 0.6025931
	class 51: 0.5176029
	class 52: 0.4024705
	class 53: 0.20299438
	class 54: 0.23760086
	class 55: 0.52160454
	class 56: 0.4355887
	class 57: 0.829871
	class 58: 0.4380976
	class 59: 0.4632953
	class 60: 0.30230862
	class 61: 0.28533775
	class 62: 0.36464185
	class 63: 0.37506878
	class 64: 0.32512954
	class 65: 0.45122153
	class 66: 0.69343597
	class 67: 0.30219898
	class 68: 0.36181638
	class 69: 0.1116176
	class 70: 0.32830787
	class 71: 0.49841103
	class 72: 0.5698284
	class 73: 0.49645004
	class 74: 0.2597292
	class 75: 0.48911268
	class 76: 0.33191437
	class 77: 0.23906495
	class 78: 0.23778039
	class 79: 0.4382537
	class 80: 0.38597485
	class 81: 0.7526202
	class 82: 0.40862325
	class 83: 0.25538394
	class 84: 0.2116096
	class 85: 0.39480972
	class 86: 0.530239
	class 87: 0.1962491
	class 88: 0.07664955
	class 89: 0.26716444
	class 90: 0.49141425
	class 91: 0.5721125
	class 92: 0.09336828
	class 93: 0.19150744
	class 94: 0.06012751
	class 95: 0.021527996
	class 96: 0.03334064
	class 97: 0.3677725
	class 98: 0.2531903
	class 99: 0.3058627
	class 100: 0.36545247
Class Acc:
	class 0: 0.53592896
	class 1: 0.8215274
	class 2: 0.8855843
	class 3: 0.9607003
	class 4: 0.85119647
	class 5: 0.8345219
	class 6: 0.8906581
	class 7: 0.8769442
	class 8: 0.92010254
	class 9: 0.73663706
	class 10: 0.7471149
	class 11: 0.629648
	class 12: 0.7364226
	class 13: 0.8538082
	class 14: 0.38614458
	class 15: 0.45532572
	class 16: 0.6081356
	class 17: 0.69282025
	class 18: 0.53087157
	class 19: 0.80641824
	class 20: 0.5976656
	class 21: 0.8643365
	class 22: 0.5887753
	class 23: 0.7385385
	class 24: 0.7358259
	class 25: 0.5435822
	class 26: 0.5745559
	class 27: 0.84667546
	class 28: 0.67704326
	class 29: 0.6073121
	class 30: 0.6138547
	class 31: 0.5207115
	class 32: 0.69408244
	class 33: 0.49432942
	class 34: 0.5658006
	class 35: 0.5652981
	class 36: 0.6324338
	class 37: 0.49280417
	class 38: 0.7667817
	class 39: 0.39050627
	class 40: 0.59375834
	class 41: 0.14447097
	class 42: 0.13106944
	class 43: 0.35556778
	class 44: 0.38285512
	class 45: 0.5949357
	class 46: 0.26585144
	class 47: 0.44365105
	class 48: 0.7292926
	class 49: 0.7288952
	class 50: 0.8054773
	class 51: 0.66365594
	class 52: 0.5826923
	class 53: 0.31802928
	class 54: 0.31063592
	class 55: 0.6925443
	class 56: 0.5537089
	class 57: 0.956583
	class 58: 0.54287255
	class 59: 0.53667825
	class 60: 0.4534933
	class 61: 0.49729204
	class 62: 0.538397
	class 63: 0.5650384
	class 64: 0.36627632
	class 65: 0.66095436
	class 66: 0.8277886
	class 67: 0.41593623
	class 68: 0.5126156
	class 69: 0.17565991
	class 70: 0.38288757
	class 71: 0.66593015
	class 72: 0.73180825
	class 73: 0.6963157
	class 74: 0.59910506
	class 75: 0.60207707
	class 76: 0.48720375
	class 77: 0.27817735
	class 78: 0.30340102
	class 79: 0.4536916
	class 80: 0.42357424
	class 81: 0.8571664
	class 82: 0.48212284
	class 83: 0.30539942
	class 84: 0.31351915
	class 85: 0.49207014
	class 86: 0.69141525
	class 87: 0.25026768
	class 88: 0.086682945
	class 89: 0.27774173
	class 90: 0.6623786
	class 91: 0.8341048
	class 92: 0.20941311
	class 93: 0.30127367
	class 94: 0.086926796
	class 95: 0.032517504
	class 96: 0.055277545
	class 97: 0.44064367
	class 98: 0.36225468
	class 99: 0.44654596
	class 100: 0.43421322

[10/20 17:19:04] LGKD INFO: Closing the Writer.
[10/20 19:30:52] LGKD INFO: [!] starting logging at directory ./logs/100-50-ade/LGKD/step0
[10/20 19:30:52] LGKD INFO: Training step 0 with lr 0.02.
[10/20 19:30:52] LGKD INFO: Dataset: ade, Train set: 20192, Val set: 2000, Test set: 2000, n_classes 101
[10/20 19:30:52] LGKD INFO: Total batch size is 16
[10/20 19:30:52] LGKD INFO: Backbone: swin_b
[10/20 19:30:53] LGKD INFO: [!] Model made with pre-trained
[10/20 19:30:53] LGKD INFO: *** Test the model on all seen classes...
[10/20 19:30:56] LGKD INFO: *** Model restored from /root/autodl-tmp/lyc/LGKD+swin/checkpoints/step/100-10-ade_LGKD_0.pth at epoch 60.
[10/20 19:34:16] LGKD INFO: Validation, Class Loss=0.9384108781814575, Reg Loss=0.0 (without scaling)
[10/20 19:34:16] LGKD INFO: Done test
[10/20 19:34:16] LGKD INFO: *** End of Test, Total Loss=0.9384108781814575, Class Loss=0.9384108781814575, Reg Loss=0.0
[10/20 19:34:16] LGKD INFO: 
Total samples: 2000.000000
Overall Acc: 0.747507
Mean Acc: 0.553111
FreqW Acc: 0.612198
Mean IoU: 0.426209
Class IoU:
	class 0: 0.37590846
	class 1: 0.66365814
	class 2: 0.760525
	class 3: 0.9124393
	class 4: 0.7119502
	class 5: 0.6879413
	class 6: 0.7630421
	class 7: 0.78080606
	class 8: 0.7473858
	class 9: 0.55782235
	class 10: 0.58451927
	class 11: 0.5100579
	class 12: 0.5608425
	class 13: 0.67186624
	class 14: 0.2859864
	class 15: 0.33349368
	class 16: 0.44107023
	class 17: 0.533591
	class 18: 0.40794063
	class 19: 0.6369821
	class 20: 0.44638622
	class 21: 0.73725355
	class 22: 0.45352596
	class 23: 0.5601405
	class 24: 0.55303675
	class 25: 0.36305207
	class 26: 0.42123997
	class 27: 0.6832902
	class 28: 0.5642341
	class 29: 0.50598735
	class 30: 0.37915364
	class 31: 0.34732485
	class 32: 0.5253317
	class 33: 0.36966497
	class 34: 0.37636596
	class 35: 0.3880517
	class 36: 0.43943575
	class 37: 0.37318087
	class 38: 0.66437876
	class 39: 0.27696833
	class 40: 0.46278659
	class 41: 0.11501391
	class 42: 0.09548542
	class 43: 0.28886658
	class 44: 0.26981914
	class 45: 0.39956892
	class 46: 0.18857789
	class 47: 0.37770313
	class 48: 0.6007592
	class 49: 0.5443519
	class 50: 0.6025931
	class 51: 0.5176029
	class 52: 0.4024705
	class 53: 0.20299438
	class 54: 0.23760086
	class 55: 0.52160454
	class 56: 0.4355887
	class 57: 0.829871
	class 58: 0.4380976
	class 59: 0.4632953
	class 60: 0.30230862
	class 61: 0.28533775
	class 62: 0.36464185
	class 63: 0.37506878
	class 64: 0.32512954
	class 65: 0.45122153
	class 66: 0.69343597
	class 67: 0.30219898
	class 68: 0.36181638
	class 69: 0.1116176
	class 70: 0.32830787
	class 71: 0.49841103
	class 72: 0.5698284
	class 73: 0.49645004
	class 74: 0.2597292
	class 75: 0.48911268
	class 76: 0.33191437
	class 77: 0.23906495
	class 78: 0.23778039
	class 79: 0.4382537
	class 80: 0.38597485
	class 81: 0.7526202
	class 82: 0.40862325
	class 83: 0.25538394
	class 84: 0.2116096
	class 85: 0.39480972
	class 86: 0.530239
	class 87: 0.1962491
	class 88: 0.07664955
	class 89: 0.26716444
	class 90: 0.49141425
	class 91: 0.5721125
	class 92: 0.09336828
	class 93: 0.19150744
	class 94: 0.06012751
	class 95: 0.021527996
	class 96: 0.03334064
	class 97: 0.3677725
	class 98: 0.2531903
	class 99: 0.3058627
	class 100: 0.36545247
Class Acc:
	class 0: 0.53592896
	class 1: 0.8215274
	class 2: 0.8855843
	class 3: 0.9607003
	class 4: 0.85119647
	class 5: 0.8345219
	class 6: 0.8906581
	class 7: 0.8769442
	class 8: 0.92010254
	class 9: 0.73663706
	class 10: 0.7471149
	class 11: 0.629648
	class 12: 0.7364226
	class 13: 0.8538082
	class 14: 0.38614458
	class 15: 0.45532572
	class 16: 0.6081356
	class 17: 0.69282025
	class 18: 0.53087157
	class 19: 0.80641824
	class 20: 0.5976656
	class 21: 0.8643365
	class 22: 0.5887753
	class 23: 0.7385385
	class 24: 0.7358259
	class 25: 0.5435822
	class 26: 0.5745559
	class 27: 0.84667546
	class 28: 0.67704326
	class 29: 0.6073121
	class 30: 0.6138547
	class 31: 0.5207115
	class 32: 0.69408244
	class 33: 0.49432942
	class 34: 0.5658006
	class 35: 0.5652981
	class 36: 0.6324338
	class 37: 0.49280417
	class 38: 0.7667817
	class 39: 0.39050627
	class 40: 0.59375834
	class 41: 0.14447097
	class 42: 0.13106944
	class 43: 0.35556778
	class 44: 0.38285512
	class 45: 0.5949357
	class 46: 0.26585144
	class 47: 0.44365105
	class 48: 0.7292926
	class 49: 0.7288952
	class 50: 0.8054773
	class 51: 0.66365594
	class 52: 0.5826923
	class 53: 0.31802928
	class 54: 0.31063592
	class 55: 0.6925443
	class 56: 0.5537089
	class 57: 0.956583
	class 58: 0.54287255
	class 59: 0.53667825
	class 60: 0.4534933
	class 61: 0.49729204
	class 62: 0.538397
	class 63: 0.5650384
	class 64: 0.36627632
	class 65: 0.66095436
	class 66: 0.8277886
	class 67: 0.41593623
	class 68: 0.5126156
	class 69: 0.17565991
	class 70: 0.38288757
	class 71: 0.66593015
	class 72: 0.73180825
	class 73: 0.6963157
	class 74: 0.59910506
	class 75: 0.60207707
	class 76: 0.48720375
	class 77: 0.27817735
	class 78: 0.30340102
	class 79: 0.4536916
	class 80: 0.42357424
	class 81: 0.8571664
	class 82: 0.48212284
	class 83: 0.30539942
	class 84: 0.31351915
	class 85: 0.49207014
	class 86: 0.69141525
	class 87: 0.25026768
	class 88: 0.086682945
	class 89: 0.27774173
	class 90: 0.6623786
	class 91: 0.8341048
	class 92: 0.20941311
	class 93: 0.30127367
	class 94: 0.086926796
	class 95: 0.032517504
	class 96: 0.055277545
	class 97: 0.44064367
	class 98: 0.36225468
	class 99: 0.44654596
	class 100: 0.43421322

[10/20 19:34:16] LGKD INFO: Closing the Writer.
